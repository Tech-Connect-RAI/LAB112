{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd63064",
   "metadata": {},
   "source": [
    "### Lab-102: Part-1\n",
    "## Fairness considerations of credit loan decisions\n",
    "In this case study, we focus on fairness in financial services, on mitigating gender-related performance disparities \n",
    "in financial lending decisions. Will explore \"how Fairlearn could be used to measure\n",
    "and mitigate unfairness in the loan adjudication process\".\n",
    "\n",
    "Using a dataset of credit loan outcomes (whether an individual defaulted on a credit loan), we train a fairness-unaware \n",
    "model to predict the likelihood an individual will default on a given loan. We use the Fairlearn toolkit for assessing \n",
    "the fairness of our model, according to several metrics. Finally, we perform two unfairness mitigation strategies on our \n",
    "model and compare the results to our original model.\n",
    "\n",
    "Task: As a Persona, I would like to develop a classification model to predict whether an applicant will default on a \n",
    "    personal loan. A positive prediction by the model means the applicant would default on the credit loan. Defaulting \n",
    "    on a loan means the client fails to make payments within a 30-day window, and the lender can take legal actions \n",
    "    against the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b3d87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    equalized_odds_difference,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.reductions import EqualizedOdds, ExponentiatedGradient\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "rand_seed = 1234\n",
    "np.random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9aca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file from a folder\n",
    "file_path = 'default of credit card clients.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "dataset=data.rename(columns={\"PAY_0\": \"PAY_1\", \"default payment next month\": \"default\"})\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40f88d",
   "metadata": {},
   "source": [
    "### Features Description\n",
    "sex, education, marriage, age : demographic features\n",
    "\n",
    "pay_0, pay_2, pay_3, pay_4, pay_5, pay_6 : repayment status (ordinal)\n",
    "\n",
    "bill_amt1, bill_amt2, bill_amt3, bill_amt4, bill_amt5, bill_amt_6 :bill statement amount (Taiwan dollars)\n",
    "\n",
    "pay_amt1, pay_amt2, pay_amt3, pay_amt4, pay_amt5, pay_amt6 :previous statement amount (Taiwan dollars)\n",
    "\n",
    "default payment next month : default information (1 = YES, 0 = NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5479832",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b8165",
   "metadata": {},
   "source": [
    "From the dataset description : We can see that there are three categorical features:\n",
    "        \n",
    "SEX: Sex of the applicant (as a binary feature)\n",
    "\n",
    "EDUCATION: Highest level of education achieved by the applicant.\n",
    "\n",
    "MARRIAGE: Marital status of the applicant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bad2ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "\n",
    "for col_name in categorical_features:\n",
    "    dataset[col_name] = dataset[col_name].astype(\"category\")\n",
    "\n",
    "Y, A = dataset.loc[:, \"default\"], dataset.loc[:, \"SEX\"]\n",
    "X = pd.get_dummies(dataset.drop(columns=[\"default\", \"SEX\"]))\n",
    "\n",
    "A_str = A.map({1: \"male\", 2: \"female\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afe95b",
   "metadata": {},
   "source": [
    "Let's explore the dataset for any characteristics that may lead to fairness-related harms later on in the modeling process.\n",
    "In particular, we will focus on the distribution of sensitive feature SEX and the target label default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_str.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c97359",
   "metadata": {},
   "source": [
    " Letâ€™s explore the distribution of the loan default rate Y. We see that around 78% of individuals in the dataset do not \n",
    " default on their credit loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bdf7b",
   "metadata": {},
   "source": [
    "Add synthetic noise that is related to the outcome and sex\n",
    "For the purpose of this case study, we add a synthetic feature Interest that introduces correlation between the SEX label \n",
    "of an applicant and the default outcome. The purpose of this feature is to replicate outcome disparities present in the \n",
    "original dataset.\n",
    "\n",
    "### This feature is drawn from a Gaussian distribution for computational simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02bf7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, \"Interest\"] = np.random.normal(loc=2 * Y, scale=A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfc55b",
   "metadata": {},
   "source": [
    "#### Check if this will lead to disparity in naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e171e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_1, ax_2) = plt.subplots(ncols=2, figsize=(10, 4), sharex=True, sharey=True)\n",
    "X[\"Interest\"][(A == 1) & (Y == 0)].plot(\n",
    "    kind=\"kde\", label=\"Payment on Time\", ax=ax_1, title=\"INTEREST for Men\"\n",
    ")\n",
    "X[\"Interest\"][(A == 1) & (Y == 1)].plot(kind=\"kde\", label=\"Payment Default\", ax=ax_1)\n",
    "X[\"Interest\"][(A == 2) & (Y == 0)].plot(\n",
    "    kind=\"kde\",\n",
    "    label=\"Payment on Time\",\n",
    "    ax=ax_2,\n",
    "    legend=True,\n",
    "    title=\"INTEREST for Women\",\n",
    ")\n",
    "X[\"Interest\"][(A == 2) & (Y == 1)].plot(\n",
    "    kind=\"kde\", label=\"Payment Default\", ax=ax_2, legend=True\n",
    ").legend(bbox_to_anchor=(1.6, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea6405",
   "metadata": {},
   "source": [
    "### Training an initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82f3d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_training_data(X_train, Y_train, A_train):\n",
    "    \"\"\"Down-sample the majority class in the training dataset to produce a\n",
    "    balanced dataset with a 50/50 split in the predictive labels.\n",
    "\n",
    "    Parameters:\n",
    "    X_train: The training split of the features\n",
    "    Y_train: The training split of the target labels\n",
    "    A_train: The training split of the sensitive features\n",
    "\n",
    "    Returns:\n",
    "    Tuple of X_train, Y_train, A_train where each dataset has been re-balanced.\n",
    "    \"\"\"\n",
    "    negative_ids = Y_train[Y_train == 0].index\n",
    "    positive_ids = Y_train[Y_train == 1].index\n",
    "    balanced_ids = positive_ids.union(np.random.choice(a=negative_ids, size=len(positive_ids)))\n",
    "\n",
    "    X_train = X_train.loc[balanced_ids, :]\n",
    "    Y_train = Y_train.loc[balanced_ids]\n",
    "    A_train = A_train.loc[balanced_ids]\n",
    "    return X_train, Y_train, A_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8def988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
    "    X, Y, A_str, test_size=0.35, stratify=Y\n",
    ")\n",
    "\n",
    "X_train, y_train, A_train = resample_training_data(X_train, y_train, A_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ecda7",
   "metadata": {},
   "source": [
    "At this stage, we will train a gradient-boosted tree classifier using the lightgbm package on the balanced training dataset. When we evaluate the model, we will use the unbalanced testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 10,\n",
    "    \"max_depth\": 3,\n",
    "    \"random_state\": rand_seed,\n",
    "    \"n_jobs\": 1,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "estimator = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessing\", StandardScaler()),\n",
    "        (\"classifier\", lgb.LGBMClassifier(**lgb_params)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f820fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_proba = estimator.predict_proba(X_test)[:, 1]\n",
    "Y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51dce2",
   "metadata": {},
   "source": [
    "From the ROC Score, we see the model appears to be differentiating between true positives and false positives well. This is to be expected given the INTEREST feature provides a strong discriminant feature for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15029f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, Y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb02ba",
   "metadata": {},
   "source": [
    "### Feature Importance of the Unmitigated Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(\n",
    "    estimator.named_steps[\"classifier\"],\n",
    "    height=0.6,\n",
    "    title=\"Feature Importance\",\n",
    "    importance_type=\"gain\",\n",
    "    max_num_features=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053698f",
   "metadata": {},
   "source": [
    "## Fairness assessment of unmitigated model\n",
    "we have trained our initial fairness-unaware model, letâ€™s perform our fairness assessment for this model. When conducting a fairness assessment, there are three main steps we want to perform:\n",
    "\n",
    "### Identify who will be harmed.\n",
    "\n",
    "### Identify the types of harms we anticipate.\n",
    "\n",
    "### Define fairness metrics based on the anticipated harms.\n",
    "Now that we have identified the relevant harms we anticipate users will experience, we can define our fairness metrics.\n",
    "In addition to the metrics, we will quantify the uncertainty around each metric using custom functions to compute the \n",
    "standard error for each metric at the confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9809e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define fairness metrics based on the anticipated harms.\n",
    "\n",
    "def compute_error_metric(metric_value, sample_size):\n",
    "    \"\"\"Compute standard error of a given metric based on the assumption of\n",
    "    normal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    metric_value: Value of the metric\n",
    "    sample_size: Number of data points associated with the metric\n",
    "\n",
    "    Returns:\n",
    "    The standard error of the metric\n",
    "    \"\"\"\n",
    "    metric_value = metric_value / sample_size\n",
    "    return 1.96 * np.sqrt(metric_value * (1.0 - metric_value)) / np.sqrt(sample_size)\n",
    "\n",
    "\n",
    "def false_positive_error(y_true, y_pred):\n",
    "    \"\"\"Compute the standard error for the false positive rate estimate.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return compute_error_metric(fp, tn + fp)\n",
    "\n",
    "\n",
    "def false_negative_error(y_true, y_pred):\n",
    "    \"\"\"Compute the standard error for the false negative rate estimate.\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return compute_error_metric(fn, fn + tp)\n",
    "\n",
    "\n",
    "def balanced_accuracy_error(y_true, y_pred):\n",
    "    \"\"\"Compute the standard error for the balanced accuracy estimate.\"\"\"\n",
    "    fpr_error, fnr_error = false_positive_error(y_true, y_pred), false_negative_error(\n",
    "        y_true, y_pred\n",
    "    )\n",
    "    return np.sqrt(fnr_error**2 + fpr_error**2) / 2\n",
    "\n",
    "\n",
    "fairness_metrics = {\n",
    "    \"count\": count,\n",
    "    \"balanced_accuracy\": balanced_accuracy_score,\n",
    "    \"balanced_acc_error\": balanced_accuracy_error,\n",
    "    \"selection_rate\": selection_rate,\n",
    "    \"false_positive_rate\": false_positive_rate,\n",
    "    \"false_positive_error\": false_positive_error,\n",
    "    \"false_negative_rate\": false_negative_rate,\n",
    "    \"false_negative_error\": false_negative_error,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3882238",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_report = [\n",
    "    \"balanced_accuracy\",\n",
    "    \"false_positive_rate\",\n",
    "    \"false_negative_rate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd11e4",
   "metadata": {},
   "source": [
    "#### Instantiate the MetricFrame for the unmitigated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricframe_unmitigated = MetricFrame(\n",
    "    metrics=fairness_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=Y_pred,\n",
    "    sensitive_features=A_test,\n",
    ")\n",
    "\n",
    "metricframe_unmitigated.by_group[metrics_to_report]\n",
    "\n",
    "metricframe_unmitigated.difference()[metrics_to_report]\n",
    "\n",
    "metricframe_unmitigated.overall[metrics_to_report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc357b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_metrics_with_error_bars(metricframe, metric, error_name):\n",
    "    \"\"\"Plot the disaggregated metric for each group with an associated\n",
    "    error bar. Both metric and the error bar are provided as columns in the\n",
    "    provided MetricFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metricframe : MetricFrame\n",
    "        The MetricFrame containing the metrics and their associated\n",
    "        uncertainty quantification.\n",
    "    metric : str\n",
    "        The metric to plot\n",
    "    error_name : str\n",
    "        The associated standard error for each metric in metric\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Matplotlib Plot of point estimates with error bars\n",
    "    \"\"\"\n",
    "    grouped_metrics = metricframe.by_group\n",
    "    point_estimates = grouped_metrics[metric]\n",
    "    error_bars = grouped_metrics[error_name]\n",
    "    lower_bounds = point_estimates - error_bars\n",
    "    upper_bounds = point_estimates + error_bars\n",
    "\n",
    "    x_axis_names = [str(name) for name in error_bars.index.to_flat_index().tolist()]\n",
    "    plt.vlines(\n",
    "        x_axis_names,\n",
    "        lower_bounds,\n",
    "        upper_bounds,\n",
    "        linestyles=\"dashed\",\n",
    "        alpha=0.45,\n",
    "    )\n",
    "    plt.scatter(x_axis_names, point_estimates, s=25)\n",
    "    plt.xticks(rotation=0)\n",
    "    y_start, y_end = np.round(min(lower_bounds), decimals=2), np.round(\n",
    "        max(upper_bounds), decimals=2\n",
    "    )\n",
    "    plt.yticks(np.arange(y_start, y_end, 0.05))\n",
    "    plt.ylabel(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_group_metrics_with_error_bars(\n",
    "    metricframe_unmitigated, \"false_positive_rate\", \"false_positive_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e363dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricframe_unmitigated.by_group[metrics_to_report].plot.bar(\n",
    "    subplots=True, layout=[1, 3], figsize=[12, 4], legend=None, rot=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bdae3",
   "metadata": {},
   "source": [
    "In our lending context, both false_negative_rate_disparities and false_positive_rate_disparities result in \n",
    "fairness-related harms. Therefore, we attempt to minimize both of these metrics by minimizing the \n",
    "equalized_odds_difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d22d90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_unmitigated = balanced_accuracy_score(y_test, Y_pred)\n",
    "equalized_odds_unmitigated = equalized_odds_difference(y_test, Y_pred, sensitive_features=A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c718d6",
   "metadata": {},
   "source": [
    "#### Mitigating Unfairness in ML models\n",
    "we will explore strategies for mitigating the performance disparities we found in our unmitigated model. \n",
    "We will apply one different mitigation strategies:\n",
    "\n",
    "#### Postprocessing: In the postprocessing approach, the outputs of a trained classifier are transformed to satisfy some fairness criterion.\n",
    "\n",
    "Reductions: In the reductions approach, we take in a model class and iteratively create a sequence of models that optimize some fairness constraint. Compared to the postprocessing approach, the fairness constraint is satisfied during the model training time rather than afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b5ba2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postprocessing mitigations: ThresholdOptimizer\n",
    "\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "    estimator=estimator,\n",
    "    constraints=\"equalized_odds\",  # Optimize FPR and FNR simultaneously\n",
    "    objective=\"balanced_accuracy_score\",\n",
    "    prefit=True,\n",
    "    predict_method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3e47c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_est.fit(X=X_train, y=y_train, sensitive_features=A_train)\n",
    "\n",
    "postprocess_pred = postprocess_est.predict(X_test, sensitive_features=A_test)\n",
    "\n",
    "postprocess_pred_proba = postprocess_est._pmf_predict(X_test, sensitive_features=A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3368cb",
   "metadata": {},
   "source": [
    "#### Fairness assessment of postprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d31c8049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metricframe_results(mframe_1, mframe_2, metrics, names):\n",
    "    \"\"\"Concatenate the results of two MetricFrames along a subset of metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mframe_1: First MetricFrame for comparison\n",
    "    mframe_2: Second MetricFrame for comparison\n",
    "    metrics: The subset of metrics for comparison\n",
    "    names: The names of the selected metrics\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MetricFrame : MetricFrame\n",
    "        The concatenation of the two MetricFrames, restricted to the metrics\n",
    "        specified.\n",
    "\n",
    "    \"\"\"\n",
    "    return pd.concat(\n",
    "        [mframe_1.by_group[metrics], mframe_2.by_group[metrics]],\n",
    "        keys=names,\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_acc_postprocess = balanced_accuracy_score(y_test, postprocess_pred)\n",
    "eq_odds_postprocess = equalized_odds_difference(\n",
    "    y_test, postprocess_pred, sensitive_features=A_test\n",
    ")\n",
    "\n",
    "metricframe_postprocess = MetricFrame(\n",
    "    metrics=fairness_metrics,\n",
    "    y_true=y_test,\n",
    "    y_pred=postprocess_pred,\n",
    "    sensitive_features=A_test,\n",
    ")\n",
    "\n",
    "metricframe_postprocess.overall[metrics_to_report]\n",
    "\n",
    "metricframe_postprocess.difference()[metrics_to_report]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99acfab",
   "metadata": {},
   "source": [
    "Now, letâ€™s compare the performance of our thresholded classifier with the original unmitigated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metricframe_results(\n",
    "    metricframe_unmitigated,\n",
    "    metricframe_postprocess,\n",
    "    metrics=metrics_to_report,\n",
    "    names=[\"Unmitigated\", \"PostProcess\"],\n",
    ")\n",
    "\n",
    "metricframe_postprocess.by_group[metrics_to_report].plot.bar(\n",
    "    subplots=True, layout=[1, 3], figsize=[12, 4], legend=None, rot=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a35552",
   "metadata": {},
   "source": [
    "#### Conclusion and Discussion\n",
    "In this case study, we walked through the process of assessing a credit decision model for gender-related performance \n",
    "disparities.Yet We havn't applied a postprocessing and reductions mitigation techniques to mitigate the equalized odds \n",
    "difference in our model.\n",
    "We applied a postprocessing to mitigate the equalized odds difference in our model.\n",
    "Through the reductions process, we generated a model that reduces the equalized odds difference of the original model \n",
    "without a drastic increase in the balanced error score. If this were a real model being developed a financial institution, \n",
    "the balanced error score would be a proxy for the profitability of the model. By maintaining a relatively similar balanced\n",
    "error score, weâ€™ve produced a model that preserves profitability to the firm while producing more fair and equitable \n",
    "outcomes for women in this scenario.\n",
    "\n",
    "Next Steps to explore:\n",
    "    Mitigating Unfairness in ML models\n",
    "    Reductions approach to unfairness mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd7dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
