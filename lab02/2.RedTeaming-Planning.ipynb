{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning AI Red Teaming\n",
    "\n",
    "### Contents\n",
    "1. [Planning AI Red Teaming](#planning-ai-red-teaming)\n",
    "   - Introduction and Session Overview\n",
    "2. [Introduction to Red Team Planning](#introduction-to-red-team-planning)\n",
    "3. [Red Teaming Activity](#red-teaming-activity)\n",
    "   - **Scenario:** Medical Glossary Chatbot\n",
    "   - Task Description\n",
    "   - Detailed Steps:\n",
    "     1. [Goal](#goal)\n",
    "        - Define the specific area(s) to test\n",
    "     2. [Assemble the Team](#assemble-the-team)\n",
    "        - List team members and assign focus areas (RAI harms)\n",
    "     3. [Design & Perform Tests](#design--perform-tests)\n",
    "        - Execute tests using the chatbot UI with code integration\n",
    "     4. [Report the Results](#report-the-results)\n",
    "        - Document findings and plan next steps\n",
    "4. [Resources](#resources)\n",
    "   - External Guides and Example Prompts\n",
    "\n",
    "\n",
    "### Overview\n",
    "This session provides a high level overview of how to plan for red teaming AI systems. \n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "By the end of this session, you will:\n",
    "1. Assemble a multidisciplinary red team to address different Responsible AI (RAI) harms.\n",
    "2. Design and perform iterative adversarial tests at both the language model and application levels.\n",
    "3. Demonstrate specific areas within a given chatbot application that require mitigations.\n",
    "4. Document findings and identify opportunities for continuous monitoring and improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Red Team Planning\n",
    "\n",
    "Planning AI red teaming exercises involves several essential steps to ensure a comprehensive and effective assessment of your AI systems. Steps include:\n",
    "\n",
    "- **Defining the Goals**: Determine the specific areas you want to test. This helps in setting clear objectives for the exercise.\n",
    "\n",
    "- **Assembling the team**: It is important to assemble a diverse red team from differnt backgrounds. Assign tasks/features to each person to probe for specific types of RAI harms, and rotate roles periodically. Clearly defined objectives should be outlined, detailing the goals of each testing round, the features and issues to be focused on, the expected time and effort required  along with detailed recording instructions to encourage reproducibility of results. Also, maintaining effective communication is crucial, and this can be achieved by identifying key contact points for any questions that may arise during the process.\n",
    "\n",
    "- **Designing & performing adversarial tests**: Red teamers should perform iterative, adversarial tests at both the LLM and application layers to identify harms. Regularly retest after applying mitigations and document results.\n",
    "\n",
    "- **Reporting results & continuous monitoring**: Record tests/results centrally and share regular reports with top issues, next testing plans and relevant info. Red teaming is an interative approach, with regular assessments. This includes weekly sprints to continually identify, measure, and mitigate risks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Teaming Activity\n",
    "\n",
    "**Scenario**: An organization called `MD Web` has developed a medical glossary AI Assistant. This intelligent tool is exclusively programmed to provide precise definitions and contextual explanations for a wide range of medical terms. Its system prompt has been designed to ensure that, while it may offer detailed explanations for technical vocabulary, it never provides treatment recommendations or direct medical advice.\n",
    "\n",
    "**Task**: Create a plan for conducting one iteration of red teaming for this chatbot. Include information about the team, the RAI harms to consider, and the techniques that will be used to test the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Goal\n",
    "\n",
    "*Determine the specific area(s) that you plan to test*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Assemble the team\n",
    "\n",
    "- **Assemble a diverse team**\n",
    "\n",
    "    *List persons who will be needed on the team. Think about the diverse backgrounds and experience that's needed for the use case*\n",
    "\n",
    "\n",
    "\n",
    "- **Assign red teamers to harms and/or features**\n",
    "\n",
    "    *For each team member listed above, which RAI harm should be their focus*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Design & Perform Tests\n",
    "\n",
    "*Perform various techniques using the chatbot UI below*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.MedicalChatbotApp import MedicalChatbot\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create an instance of the Chatbot class\n",
    "bot = MedicalChatbot()\n",
    "bot.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Report the results\n",
    "\n",
    "*What were the findings?*\n",
    "\n",
    "\n",
    "*What is your plan for the next iteration of testing*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "This notebook introduces a structured approach for planning RAI red teaming exercises, with a use case of a medical glossary AI assistant. It guides users through setting clear testing goals, assembling a diverse red teaming group, designing and executing iterative adversarial tests on both the language model and application layers, and finally reporting and documenting test results. \n",
    "\n",
    "**Key Takeaways**:\n",
    "\n",
    "- Structured & Iterative Testing:\n",
    "The methodology stresses a cyclical testing process that includes clearly defined objectives and iterative reassessment to continuously mitigate potential Responsible AI harms.\n",
    "\n",
    "- Team Diversity:\n",
    "Assembling a diverse red team with clear role assignments based on expertise ensures comprehensive coverage of risk areas, enabling more effective identification and mitigation of vulnerabilities.\n",
    "\n",
    "\n",
    "Next Step:\n",
    "- Lab 3: Automating Red Teaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "- [Planning red teaming for large language models (LLMs) and their applications](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming)\n",
    "    - https://aka.ms/red-teaming-planning-guide\n",
    "- [Introduction to AI security testing](https://learn.microsoft.com/en-us/training/modules/introduction-ai-security-testing/)\n",
    "\n",
    "- https://aka.ms/LLM-red-teamer-instructions-TEMPLATE\n",
    "\n",
    "- [Example prompts](https://aka.ms/RAIRedTeamExamplePrompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
